#!/bin/bash

function _getLatestDumpSql() {
    LATEST_DUMP="$(aws s3 ls "s3://$BACKUP_BUCKET/" | sort | tail -n 1 | awk '{print $4}' | sed 's/\.gz//')"
    printf 'Latest database backup is "%s.gz"\n' "$LATEST_DUMP" >&2
    aws s3 cp --no-progress "s3://$BACKUP_BUCKET/$LATEST_DUMP.gz" - | gunzip
}

_psqlExec() {
    PGPASSWORD="$POSTGRES_PASSWORD" psql -h "$POSTGRES_HOST" -U "$POSTGRES_USERNAME" "$POSTGRES_DATABASE" "$@"
}

function _importDataDump() {
    printf 'Importing dump into "%s"\n' "$POSTGRES_HOST" >&2

    if [[ -n "${SCHEMA_TO_DROP:-}" ]]; then
        printf 'Dropping schema "%s"\n' "$SCHEMA_TO_DROP"
        _psqlExec <<< "DROP SCHEMA $SCHEMA_TO_DROP CASCADE; CREATE SCHEMA $SCHEMA_TO_DROP; GRANT ALL ON SCHEMA $SCHEMA_TO_DROP TO $SCHEMA_TO_DROP;"
    fi

    _psqlExec -f <(_getLatestDumpSql)
}

function _syncS3Bucket() {
    printf 'Syncing S3 bucket "s3://%s/" to "s3://%s/"\n' "$FROM_BUCKET" "$TO_BUCKET" >&2
    aws s3 sync --no-progress ${DELETE:+--delete} "s3://$FROM_BUCKET/" "s3://$TO_BUCKET/"
}

function _createDownJson() {
    jq -n --arg time "$(date +%s)" '{"time": $time | tonumber, "message": "Updating to match production. Please retry in 1 minute.", "retry": null, "allowed": []}'
}

function _main() {
    IFS=$'\n\t'
    set -euo pipefail

    if [[ -n "${DOWN_FILE:-}" ]]; then
        _createDownJson > "$DOWN_FILE"
    fi

    if [[ -n "${BACKUP_BUCKET:-}" && -n "${POSTGRES_HOST:-}" && -n "${POSTGRES_USERNAME:-}" && -n "${POSTGRES_DATABASE:-}" && -n "${POSTGRES_PASSWORD:-}" ]]; then
        _importDataDump
    else
        echo 'Not all variables are set for database import.' >&2
    fi

    if [[ -n "${FROM_BUCKET:-}" && -n "${TO_BUCKET:-}" ]]; then
        _syncS3Bucket
    else
        echo 'Not all variables are set for S3 sync.' >&2
    fi

    if [[ -n "${MIGRATE_FILE:-}" ]]; then
        touch "$MIGRATE_FILE"
    fi

    echo 'Done!' >&2
}

if [[ "$0" = "${BASH_SOURCE[0]}" ]]; then
    _main "$@"
fi
